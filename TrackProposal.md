

Large Language Models (LLMs) in Python
======================================

Large Language Models (LLMs) that power cutting edge chat systems and conversational agents like ChatGTP.  In this track you'll gain the Natural Language Processing (NLP) and Deep learning foundations in Python and PyTorch to understand the latest LLM developments.   You'll start by mastering the classic NLP approaches and techniques and how they underpin the LLM revolution.  You'll also get hands on with Deep Learning techniques in PyTorch and see how to construct your own transformer LLM from scratch.  LLMs take extraordinary amounts of GPU cycles to train, so you'll also discover how to take full advantage of transfer learning, i.e. access the multitude of pre-trained LLMs.  By the end of the track you'll know how to select the best LLM model for different NLP tasks and how to get up and running with LLM pipelines so that you can quickly and easily deliver high quality summarisation, machine translation, question answering, text generation and other NLP solutions.

Courses include:

- Introduction to NLP in Python
- Feature Engineering for NLP in Python
- Advanced NLP with spaCy
- Deep Learning with PyTorch
- Deep Learning for Text with PyTorch
- Transformer LLMs with PyTorch
- Advanced Transformer LLMs with PyTorch


Pre-requisites for this track relate to the programming skills and machine learning concepts that various of the courses assume the learner is already familiar with, specifically:

- Python data science programming (e.g. from DataCamp's Python Data Science Toolbox courses)
- deep learning architectures including RNNs, CNNs, and LSTMs, (e.g. from DataCamp's Intro to Deep Learning in Python and RNNs for language modeling Python)
- explored optimization techniques including AdaGrad, RMSProp, and Adam (e.g. from DataCamp's Introduction to Tensorflow in Python)


Introduction to NLP in Python
-----------------------------

You'll learn natural language processing (NLP) basics, such as how to identify and separate words, how to extract topics in a text, and how to build your own fake news classifier. You'll also learn how to use basic libraries such as NLTK, alongside libraries which utilize deep learning to solve common NLP problems. This course will give you the foundation to process and parse text as you move forward in your Python learning.

### Learning Objectives

* Be able to tokenise text data
* Be able to operationalise NLP models such as bag of words and TFiDF
* Be able to implement a supervised NLP machine learning model


Feature Engineering for NLP in Python
-------------------------------------

You'll learn techniques to extract useful information from text and convert them for use by ML models., e.g. POS tagging, named entity recognition, readability scores, the n-gram and tf-idf models, and how to implement them using scikit-learn and spaCy. You will also learn to compute how similar two documents are to each other, and develop recommenders for movies and Ted Talks. Ultimately, you'll be able to engineer critical features out of any text and solve some of the most challenging problems in data science!

### Learning Objectives

* Be able to extract ML appropriate features from text data
* Understand the range of possibilities for computing document similarity
* Be able to build a text based recommender system


Advanced NLP with spaCy
-------------------------

Learn how to use spaCy, a popular library for NLP in Python, using both rule-based and machine learning approaches. For example, what's is a piece of text about? What do the words mean in context? Who is doing what to whom? What companies and products are mentioned? Which texts are similar to each other?  By the end of this course you'll have mastered using spaCy for NLP tasks

### Learning Objectives

* Be able to manipulate spaCy's processing pipelines
* Be able to use custom attributes to add your own meta data to the documents, spans and tokens
* Be able to train a model to predict a new entity type


Deep Learning with PyTorch
--------------------------

Get hands on with revolutionary deep learning approaches in PyTorch. Go from simple Neural Nets (NNs) to their more complex convolutional cousins (CNNs). Having mastered basic NN concepts you'll build a model to predict real world handwritten digits.  You'll discover how to make NNs work well in practice using concepts like regularisation, batch-normalisation and transfer learning.

### Learning Objectives

* Be able to code and train a deep NN in PyTorch
* Be able to evaluate a deep NN
* Understand and apply regularisation, batch-normalisation and transfer learning


Deep Learning for Text with PyTorch
-----------------------------------

Get started with deep learning for text using Python. You'll discover use cases of deep learning for natural language processing (NLP) and generation, as well as text classification, using a variety of NLP methods and deep learning concepts. Through hands on exercises with transformers, pipelines, tokens, and embedding you'll learn how to: split data, train and evaluate your models, save and load them, and make predictions on unseen text data.

### Learning Objectives

* Be able to access large datasets
* Train models on NLP tasks using PyTorch
* Manipulate pre-trained transformer NLP models


Transformer LLMs with PyTorch
-----------------------------

Transformers are revolutionising the world of Natural Language Processing (NLP).  Understand in depth how they are having an impact across multiple industries, how Transformer models work, and how to access off the shelf models and datasets.  Learn how to fine tune a Transformer on data for your own custom problem domain, and then share your results with others.  By the end of this course you'll be able to create pipelines to solve all the most common NLP problems such as summarisation, classification, generation question answering, and machine translation

### Learning Objectives

* Understand how Transformers work
* Be able to fine tune a model with Trainer API or Keras
* Be able to share transformer models and tokenisers


Advanced Transformer LLMs with PyTorch
--------------------------------------

Learn about some advanced applications of Transformer Large Language Models (LLMs) to areas like speech processing and computer vision.  In addition you'll get experience building and sharing demos of your models and learn the techniques required to optimise them for production environments.  At the end of the course you'll be able to apply transformers to a very wide range of machine learning problems.

### Learning Objectives

* Be able to build and share demos of your Transformer models
* Be able to optimise Transformer models for production environments
* Be able to extend transformers to tasks in speech processing and computer vision



